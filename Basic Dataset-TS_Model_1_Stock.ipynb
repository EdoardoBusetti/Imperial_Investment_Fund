{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "from sklearn import preprocessing\n",
    "from sklearn import model_selection\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import SimpleRNN\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.assign(Ret1M  = data.Close.groupby(data.Tick).pct_change(1))\n",
    "data = data.assign(Ret3M  = data.Close.groupby(data.Tick).pct_change(3))\n",
    "data = data.assign(Ret6M  = data.Close.groupby(data.Tick).pct_change(6))\n",
    "data = data.assign(Ret12M = data.Close.groupby(data.Tick).pct_change(12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.assign(MOM3M  = data.Close.groupby(data.Tick).shift(1)/data.Close.groupby(data.Tick).shift(4)  - 1)\n",
    "data = data.assign(MOM6M  = data.Close.groupby(data.Tick).shift(1)/data.Close.groupby(data.Tick).shift(6)  - 1)\n",
    "data = data.assign(MOM12M = data.Close.groupby(data.Tick).shift(1)/data.Close.groupby(data.Tick).shift(12) - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing \"Date\" to datetime format\n",
    "data['Date'] = pd.to_datetime(data['Date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have data about 209 stocks and 232 timepoints (months)\n",
    "These are the columns in the dataset:\n",
    "\n",
    "**'Tick' 'Date'   'Close'   'Mkt_Cap' 'P2B' 'Vol_1M' 'Div_yield' 'PE_ratio'**\n",
    "\n",
    " **'RSI_1M' 'D2E' 'Prof_growth' 'Ret_Cap' 'Asset_growth' 'Prof_Marg' 'Ret1M'**\n",
    " \n",
    " **'Ret3M' 'Ret6M' 'Ret12M' 'MOM3M' 'MOM6M' 'MOM12M'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# See avaiable ticks\n",
    "# with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "#     print(sorted(set(data.Tick)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(axis=0, how='any',inplace=True) # Drop first 12 rows since we dont' have some factors (e.g. ret12) # Also, we might now need data from 1999 to predict current movements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "### From GitHub ###\n",
    "\n",
    "#Sets index of dataframe to the stock's tick for sorting purposes\n",
    "data.set_index(\"Tick\",inplace=True)\n",
    "\n",
    "#Extracts data for individual stock\n",
    "def get_stock_data(data,stock):\n",
    "    return data.loc[stock]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardising the data - Cross sectional MinMax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "numeric_columns = list(data.columns.values[data.dtypes.values == float]) # Keeeping only numeric columns\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(0,1)) #Defyning the scalar object\n",
    "\n",
    "def get_cross_section(data,date): # Used\n",
    "    return data[data.Date == date]\n",
    "\n",
    "\n",
    "standardized_data = pd.DataFrame(columns = list(data.columns.values).append(\"Quintile\"))\n",
    "\n",
    "for date in set(data.Date.values):\n",
    "    CS_numeric_date = get_cross_section(data,date)[numeric_columns] # Extracting numeric columns from the cross section\n",
    "    transformed = scaler.fit_transform(CS_numeric_date) # cross-sectional standardization\n",
    "    scaled_features_df = pd.DataFrame(transformed, index=CS_numeric_date.index, columns=CS_numeric_date.columns) # transforming into dataframe\n",
    "    scaled_features_df.insert(0, \"Date\", date) # Adding back the corresponding date\n",
    "    \n",
    "    \n",
    "    ################ Calculating quintiles ##################\n",
    "    q_20 = scaled_features_df[\"Ret1M\"].quantile(q=0.2, interpolation='linear')\n",
    "    q_40 = scaled_features_df[\"Ret1M\"].quantile(q=0.4, interpolation='linear')\n",
    "    q_60 = scaled_features_df[\"Ret1M\"].quantile(q=0.6, interpolation='linear')\n",
    "    q_80 = scaled_features_df[\"Ret1M\"].quantile(q=0.8, interpolation='linear')\n",
    "    \n",
    "    # Encoding: 4 is in 1st quantile, 3 if in second quantile ...\n",
    "    idx1 = np.where((scaled_features_df['Ret1M']<= q_20))\n",
    "    idx2 = np.where((scaled_features_df['Ret1M']> q_20) & (scaled_features_df['Ret1M']<= q_40))\n",
    "    idx3 = np.where((scaled_features_df['Ret1M']> q_40) & (scaled_features_df['Ret1M']<= q_60))\n",
    "    idx4 = np.where((scaled_features_df['Ret1M']> q_60) & (scaled_features_df['Ret1M']<= q_80))\n",
    "    idx5 = np.where((scaled_features_df['Ret1M']> q_80))\n",
    "    \n",
    "    scaled_features_df[\"Quintile\"] = 999 # Initializing value\n",
    "    scaled_features_df[\"Quintile\"].iloc[idx1] = 0\n",
    "    scaled_features_df[\"Quintile\"].iloc[idx2] = 1\n",
    "    scaled_features_df[\"Quintile\"].iloc[idx3] = 2\n",
    "    scaled_features_df[\"Quintile\"].iloc[idx4] = 3\n",
    "    scaled_features_df[\"Quintile\"].iloc[idx5] = 4\n",
    "    \n",
    "    \n",
    "    standardized_data = pd.concat([standardized_data, scaled_features_df]) # Adding the data from this date to the whole standardized database\n",
    "    \n",
    "    \n",
    "standardized_data.sort_values(by=['Date'],inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quintiles Check\n",
    "I suggest to consider the quintiles as values and not as classes in the model. So that we can keep the information that 1s quintile > 2nd quintile > ... > 5th quintile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ret1M</th>\n",
       "      <th>Quintile</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tick</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>XRX</th>\n",
       "      <td>0.519769</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AA</th>\n",
       "      <td>0.676183</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MTW</th>\n",
       "      <td>0.800614</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MUR</th>\n",
       "      <td>0.816520</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MYL</th>\n",
       "      <td>0.782999</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ETR</th>\n",
       "      <td>0.786441</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F</th>\n",
       "      <td>0.656175</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FAST</th>\n",
       "      <td>0.818582</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FCX</th>\n",
       "      <td>0.691333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EIX</th>\n",
       "      <td>0.658974</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>209 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Ret1M  Quintile\n",
       "Tick                    \n",
       "XRX   0.519769         0\n",
       "AA    0.676183         1\n",
       "MTW   0.800614         4\n",
       "MUR   0.816520         4\n",
       "MYL   0.782999         4\n",
       "...        ...       ...\n",
       "ETR   0.786441         4\n",
       "F     0.656175         1\n",
       "FAST  0.818582         4\n",
       "FCX   0.691333         1\n",
       "EIX   0.658974         1\n",
       "\n",
       "[209 rows x 2 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking quintiles\n",
    "standardized_data['Quintile'].value_counts()\n",
    "\n",
    "# The higher the std 1 month returns, the higher the quintile value.\n",
    "standardized_data[standardized_data['Date'] == date][[\"Ret1M\",\"Quintile\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shifting Quintiles to make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "standardized_data_with_target = pd.DataFrame(columns = list(standardized_data.columns.values).append(\"Target_Shifted_Quintile_1\"))\n",
    "\n",
    "for tick in set(standardized_data.index.values):\n",
    "    TS_tick = standardized_data[standardized_data.index == tick]\n",
    "    \n",
    "    \n",
    "    TS_tick[\"Target_Shifted_Quintile_1\"] = TS_tick[[\"Quintile\"]].shift(-1)\n",
    "    TS_tick[\"Target_Shifted_Quintile_1\"][-1] = 999 # Before converting to int we have to get rid of the nan (last value of the shifted)\n",
    "    TS_tick[\"Target_Shifted_Quintile_1\"] = TS_tick[\"Target_Shifted_Quintile_1\"].astype(int)\n",
    "    \n",
    "    standardized_data_with_target = pd.concat([standardized_data_with_target, TS_tick]) # Adding the data from this date to the whole standardized database\n",
    "    \n",
    "    \n",
    "standardized_data_with_target[\"Temp\"] = standardized_data_with_target.index\n",
    "standardized_data_with_target.sort_values(by=['Date', 'Temp'], inplace=True)\n",
    "standardized_data_with_target.sort_values(by=['Date', 'Temp'], inplace=True)\n",
    "standardized_data_with_target.drop(['Temp'],axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop the last timestep - We don't have the target for it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "standardized_data_with_target.reset_index(level=0, inplace=True)\n",
    "\n",
    "standardized_data_with_target.drop(standardized_data_with_target[standardized_data_with_target.Target_Shifted_Quintile_1 == 999].index,axis='rows',inplace = True)\n",
    "\n",
    "standardized_data_with_target.set_index(\"Tick\",inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_32\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_32 (LSTM)               (None, 4)                 400       \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 425\n",
      "Trainable params: 425\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# RNN input_shape: (Samples,Time Steps, Features)\n",
    "# Samples. One sequence is one sample. A batch is comprised of one or more samples.\n",
    "# Time Steps. One time step is one point of observation in the sample.\n",
    "# Features. One feature is one observation at a time step.\n",
    "\n",
    "time_steps  = 2\n",
    "\n",
    "input_shape=(time_steps, 20) # 1 or more samples, time_steps time steps, and 20 features.\n",
    "# create and fit the LSTM network\n",
    "\n",
    "reg_par = 0.006\n",
    "model = Sequential()\n",
    "model.add(LSTM(4, input_shape=input_shape,kernel_regularizer=l2(reg_par), recurrent_regularizer=l2(reg_par), bias_regularizer=l2(reg_par))) #activation=\"tanh\" default\n",
    "model.add(Dense(4))\n",
    "model.add(Dense(1))\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.00004)\n",
    "model.compile(loss='mean_squared_error', optimizer=opt)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct Dataset for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separates data into target (Closing Price) and predictors (excluding date)\n",
    "def split_stock_data(stock_data):\n",
    "    y = stock_data['Target_Shifted_Quintile_1']\n",
    "    X = stock_data.drop(['Target_Shifted_Quintile_1','Date'],axis='columns', inplace=False) #This way we don't remove the data information from the dataset\n",
    "    return X,y\n",
    "\n",
    "\n",
    "\n",
    "def create_dataset(X, y, time_steps=1):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(len(X) - time_steps):\n",
    "        v = X.iloc[i:(i + time_steps)].values\n",
    "        Xs.append(v)\n",
    "        ys.append(y.iloc[i + time_steps])\n",
    "    return np.array(Xs), np.array(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "17/17 - 0s - loss: 6.4973 - val_loss: 6.6392\n",
      "Epoch 2/400\n",
      "17/17 - 0s - loss: 6.4732 - val_loss: 6.6123\n",
      "Epoch 3/400\n",
      "17/17 - 0s - loss: 6.4492 - val_loss: 6.5855\n",
      "Epoch 4/400\n",
      "17/17 - 0s - loss: 6.4253 - val_loss: 6.5586\n",
      "Epoch 5/400\n",
      "17/17 - 0s - loss: 6.4013 - val_loss: 6.5317\n",
      "Epoch 6/400\n",
      "17/17 - 0s - loss: 6.3774 - val_loss: 6.5048\n",
      "Epoch 7/400\n",
      "17/17 - 0s - loss: 6.3535 - val_loss: 6.4778\n",
      "Epoch 8/400\n",
      "17/17 - 0s - loss: 6.3296 - val_loss: 6.4507\n",
      "Epoch 9/400\n",
      "17/17 - 0s - loss: 6.3056 - val_loss: 6.4235\n",
      "Epoch 10/400\n",
      "17/17 - 0s - loss: 6.2816 - val_loss: 6.3963\n",
      "Epoch 11/400\n",
      "17/17 - 0s - loss: 6.2575 - val_loss: 6.3689\n",
      "Epoch 12/400\n",
      "17/17 - 0s - loss: 6.2334 - val_loss: 6.3414\n",
      "Epoch 13/400\n",
      "17/17 - 0s - loss: 6.2093 - val_loss: 6.3139\n",
      "Epoch 14/400\n",
      "17/17 - 0s - loss: 6.1851 - val_loss: 6.2862\n",
      "Epoch 15/400\n",
      "17/17 - 0s - loss: 6.1608 - val_loss: 6.2583\n",
      "Epoch 16/400\n",
      "17/17 - 0s - loss: 6.1365 - val_loss: 6.2304\n",
      "Epoch 17/400\n",
      "17/17 - 0s - loss: 6.1121 - val_loss: 6.2024\n",
      "Epoch 18/400\n",
      "17/17 - 0s - loss: 6.0876 - val_loss: 6.1742\n",
      "Epoch 19/400\n",
      "17/17 - 0s - loss: 6.0630 - val_loss: 6.1459\n",
      "Epoch 20/400\n",
      "17/17 - 0s - loss: 6.0384 - val_loss: 6.1175\n",
      "Epoch 21/400\n",
      "17/17 - 0s - loss: 6.0137 - val_loss: 6.0889\n",
      "Epoch 22/400\n",
      "17/17 - 0s - loss: 5.9889 - val_loss: 6.0602\n",
      "Epoch 23/400\n",
      "17/17 - 0s - loss: 5.9640 - val_loss: 6.0315\n",
      "Epoch 24/400\n",
      "17/17 - 0s - loss: 5.9390 - val_loss: 6.0025\n",
      "Epoch 25/400\n",
      "17/17 - 0s - loss: 5.9140 - val_loss: 5.9735\n",
      "Epoch 26/400\n",
      "17/17 - 0s - loss: 5.8889 - val_loss: 5.9444\n",
      "Epoch 27/400\n",
      "17/17 - 0s - loss: 5.8637 - val_loss: 5.9151\n",
      "Epoch 28/400\n",
      "17/17 - 0s - loss: 5.8384 - val_loss: 5.8858\n",
      "Epoch 29/400\n",
      "17/17 - 0s - loss: 5.8131 - val_loss: 5.8563\n",
      "Epoch 30/400\n",
      "17/17 - 0s - loss: 5.7877 - val_loss: 5.8268\n",
      "Epoch 31/400\n",
      "17/17 - 0s - loss: 5.7622 - val_loss: 5.7971\n",
      "Epoch 32/400\n",
      "17/17 - 0s - loss: 5.7367 - val_loss: 5.7674\n",
      "Epoch 33/400\n",
      "17/17 - 0s - loss: 5.7110 - val_loss: 5.7376\n",
      "Epoch 34/400\n",
      "17/17 - 0s - loss: 5.6854 - val_loss: 5.7078\n",
      "Epoch 35/400\n",
      "17/17 - 0s - loss: 5.6596 - val_loss: 5.6778\n",
      "Epoch 36/400\n",
      "17/17 - 0s - loss: 5.6339 - val_loss: 5.6478\n",
      "Epoch 37/400\n",
      "17/17 - 0s - loss: 5.6080 - val_loss: 5.6178\n",
      "Epoch 38/400\n",
      "17/17 - 0s - loss: 5.5821 - val_loss: 5.5877\n",
      "Epoch 39/400\n",
      "17/17 - 0s - loss: 5.5562 - val_loss: 5.5576\n",
      "Epoch 40/400\n",
      "17/17 - 0s - loss: 5.5303 - val_loss: 5.5274\n",
      "Epoch 41/400\n",
      "17/17 - 0s - loss: 5.5043 - val_loss: 5.4973\n",
      "Epoch 42/400\n",
      "17/17 - 0s - loss: 5.4783 - val_loss: 5.4671\n",
      "Epoch 43/400\n",
      "17/17 - 0s - loss: 5.4522 - val_loss: 5.4369\n",
      "Epoch 44/400\n",
      "17/17 - 0s - loss: 5.4262 - val_loss: 5.4067\n",
      "Epoch 45/400\n",
      "17/17 - 0s - loss: 5.4001 - val_loss: 5.3765\n",
      "Epoch 46/400\n",
      "17/17 - 0s - loss: 5.3740 - val_loss: 5.3464\n",
      "Epoch 47/400\n",
      "17/17 - 0s - loss: 5.3479 - val_loss: 5.3162\n",
      "Epoch 48/400\n",
      "17/17 - 0s - loss: 5.3219 - val_loss: 5.2861\n",
      "Epoch 49/400\n",
      "17/17 - 0s - loss: 5.2958 - val_loss: 5.2561\n",
      "Epoch 50/400\n",
      "17/17 - 0s - loss: 5.2697 - val_loss: 5.2261\n",
      "Epoch 51/400\n",
      "17/17 - 0s - loss: 5.2437 - val_loss: 5.1961\n",
      "Epoch 52/400\n",
      "17/17 - 0s - loss: 5.2177 - val_loss: 5.1662\n",
      "Epoch 53/400\n",
      "17/17 - 0s - loss: 5.1917 - val_loss: 5.1364\n",
      "Epoch 54/400\n",
      "17/17 - 0s - loss: 5.1657 - val_loss: 5.1067\n",
      "Epoch 55/400\n",
      "17/17 - 0s - loss: 5.1398 - val_loss: 5.0770\n",
      "Epoch 56/400\n",
      "17/17 - 0s - loss: 5.1139 - val_loss: 5.0475\n",
      "Epoch 57/400\n",
      "17/17 - 0s - loss: 5.0881 - val_loss: 5.0180\n",
      "Epoch 58/400\n",
      "17/17 - 0s - loss: 5.0623 - val_loss: 4.9886\n",
      "Epoch 59/400\n",
      "17/17 - 0s - loss: 5.0366 - val_loss: 4.9594\n",
      "Epoch 60/400\n",
      "17/17 - 0s - loss: 5.0109 - val_loss: 4.9302\n",
      "Epoch 61/400\n",
      "17/17 - 0s - loss: 4.9853 - val_loss: 4.9012\n",
      "Epoch 62/400\n",
      "17/17 - 0s - loss: 4.9597 - val_loss: 4.8723\n",
      "Epoch 63/400\n",
      "17/17 - 0s - loss: 4.9342 - val_loss: 4.8435\n",
      "Epoch 64/400\n",
      "17/17 - 0s - loss: 4.9088 - val_loss: 4.8148\n",
      "Epoch 65/400\n",
      "17/17 - 0s - loss: 4.8835 - val_loss: 4.7863\n",
      "Epoch 66/400\n",
      "17/17 - 0s - loss: 4.8583 - val_loss: 4.7580\n",
      "Epoch 67/400\n",
      "17/17 - 0s - loss: 4.8331 - val_loss: 4.7297\n",
      "Epoch 68/400\n",
      "17/17 - 0s - loss: 4.8080 - val_loss: 4.7017\n",
      "Epoch 69/400\n",
      "17/17 - 0s - loss: 4.7830 - val_loss: 4.6737\n",
      "Epoch 70/400\n",
      "17/17 - 0s - loss: 4.7581 - val_loss: 4.6460\n",
      "Epoch 71/400\n",
      "17/17 - 0s - loss: 4.7333 - val_loss: 4.6183\n",
      "Epoch 72/400\n",
      "17/17 - 0s - loss: 4.7086 - val_loss: 4.5909\n",
      "Epoch 73/400\n",
      "17/17 - 0s - loss: 4.6840 - val_loss: 4.5636\n",
      "Epoch 74/400\n",
      "17/17 - 0s - loss: 4.6594 - val_loss: 4.5365\n",
      "Epoch 75/400\n",
      "17/17 - 0s - loss: 4.6350 - val_loss: 4.5095\n",
      "Epoch 76/400\n",
      "17/17 - 0s - loss: 4.6107 - val_loss: 4.4827\n",
      "Epoch 77/400\n",
      "17/17 - 0s - loss: 4.5865 - val_loss: 4.4561\n",
      "Epoch 78/400\n",
      "17/17 - 0s - loss: 4.5624 - val_loss: 4.4296\n",
      "Epoch 79/400\n",
      "17/17 - 0s - loss: 4.5384 - val_loss: 4.4033\n",
      "Epoch 80/400\n",
      "17/17 - 0s - loss: 4.5145 - val_loss: 4.3772\n",
      "Epoch 81/400\n",
      "17/17 - 0s - loss: 4.4907 - val_loss: 4.3513\n",
      "Epoch 82/400\n",
      "17/17 - 0s - loss: 4.4670 - val_loss: 4.3255\n",
      "Epoch 83/400\n",
      "17/17 - 0s - loss: 4.4435 - val_loss: 4.2999\n",
      "Epoch 84/400\n",
      "17/17 - 0s - loss: 4.4200 - val_loss: 4.2745\n",
      "Epoch 85/400\n",
      "17/17 - 0s - loss: 4.3967 - val_loss: 4.2492\n",
      "Epoch 86/400\n",
      "17/17 - 0s - loss: 4.3734 - val_loss: 4.2241\n",
      "Epoch 87/400\n",
      "17/17 - 0s - loss: 4.3503 - val_loss: 4.1992\n",
      "Epoch 88/400\n",
      "17/17 - 0s - loss: 4.3273 - val_loss: 4.1745\n",
      "Epoch 89/400\n",
      "17/17 - 0s - loss: 4.3044 - val_loss: 4.1499\n",
      "Epoch 90/400\n",
      "17/17 - 0s - loss: 4.2816 - val_loss: 4.1255\n",
      "Epoch 91/400\n",
      "17/17 - 0s - loss: 4.2590 - val_loss: 4.1013\n",
      "Epoch 92/400\n",
      "17/17 - 0s - loss: 4.2364 - val_loss: 4.0772\n",
      "Epoch 93/400\n",
      "17/17 - 0s - loss: 4.2140 - val_loss: 4.0533\n",
      "Epoch 94/400\n",
      "17/17 - 0s - loss: 4.1916 - val_loss: 4.0296\n",
      "Epoch 95/400\n",
      "17/17 - 0s - loss: 4.1694 - val_loss: 4.0060\n",
      "Epoch 96/400\n",
      "17/17 - 0s - loss: 4.1473 - val_loss: 3.9826\n",
      "Epoch 97/400\n",
      "17/17 - 0s - loss: 4.1253 - val_loss: 3.9594\n",
      "Epoch 98/400\n",
      "17/17 - 0s - loss: 4.1034 - val_loss: 3.9363\n",
      "Epoch 99/400\n",
      "17/17 - 0s - loss: 4.0816 - val_loss: 3.9134\n",
      "Epoch 100/400\n",
      "17/17 - 0s - loss: 4.0599 - val_loss: 3.8906\n",
      "Epoch 101/400\n",
      "17/17 - 0s - loss: 4.0383 - val_loss: 3.8680\n",
      "Epoch 102/400\n",
      "17/17 - 0s - loss: 4.0169 - val_loss: 3.8456\n",
      "Epoch 103/400\n",
      "17/17 - 0s - loss: 3.9955 - val_loss: 3.8233\n",
      "Epoch 104/400\n",
      "17/17 - 0s - loss: 3.9743 - val_loss: 3.8012\n",
      "Epoch 105/400\n",
      "17/17 - 0s - loss: 3.9532 - val_loss: 3.7792\n",
      "Epoch 106/400\n",
      "17/17 - 0s - loss: 3.9321 - val_loss: 3.7574\n",
      "Epoch 107/400\n",
      "17/17 - 0s - loss: 3.9112 - val_loss: 3.7357\n",
      "Epoch 108/400\n",
      "17/17 - 0s - loss: 3.8904 - val_loss: 3.7142\n",
      "Epoch 109/400\n",
      "17/17 - 0s - loss: 3.8697 - val_loss: 3.6928\n",
      "Epoch 110/400\n",
      "17/17 - 0s - loss: 3.8491 - val_loss: 3.6716\n",
      "Epoch 111/400\n",
      "17/17 - 0s - loss: 3.8286 - val_loss: 3.6505\n",
      "Epoch 112/400\n",
      "17/17 - 0s - loss: 3.8083 - val_loss: 3.6295\n",
      "Epoch 113/400\n",
      "17/17 - 0s - loss: 3.7880 - val_loss: 3.6087\n",
      "Epoch 114/400\n",
      "17/17 - 0s - loss: 3.7679 - val_loss: 3.5881\n",
      "Epoch 115/400\n",
      "17/17 - 0s - loss: 3.7478 - val_loss: 3.5676\n",
      "Epoch 116/400\n",
      "17/17 - 0s - loss: 3.7279 - val_loss: 3.5472\n",
      "Epoch 117/400\n",
      "17/17 - 0s - loss: 3.7081 - val_loss: 3.5270\n",
      "Epoch 118/400\n",
      "17/17 - 0s - loss: 3.6884 - val_loss: 3.5069\n",
      "Epoch 119/400\n",
      "17/17 - 0s - loss: 3.6688 - val_loss: 3.4870\n",
      "Epoch 120/400\n",
      "17/17 - 0s - loss: 3.6493 - val_loss: 3.4672\n",
      "Epoch 121/400\n",
      "17/17 - 0s - loss: 3.6300 - val_loss: 3.4476\n",
      "Epoch 122/400\n",
      "17/17 - 0s - loss: 3.6107 - val_loss: 3.4281\n",
      "Epoch 123/400\n",
      "17/17 - 0s - loss: 3.5916 - val_loss: 3.4087\n",
      "Epoch 124/400\n",
      "17/17 - 0s - loss: 3.5726 - val_loss: 3.3895\n",
      "Epoch 125/400\n",
      "17/17 - 0s - loss: 3.5538 - val_loss: 3.3704\n",
      "Epoch 126/400\n",
      "17/17 - 0s - loss: 3.5350 - val_loss: 3.3515\n",
      "Epoch 127/400\n",
      "17/17 - 0s - loss: 3.5164 - val_loss: 3.3328\n",
      "Epoch 128/400\n",
      "17/17 - 0s - loss: 3.4979 - val_loss: 3.3141\n",
      "Epoch 129/400\n",
      "17/17 - 0s - loss: 3.4796 - val_loss: 3.2957\n",
      "Epoch 130/400\n",
      "17/17 - 0s - loss: 3.4614 - val_loss: 3.2774\n",
      "Epoch 131/400\n",
      "17/17 - 0s - loss: 3.4433 - val_loss: 3.2592\n",
      "Epoch 132/400\n",
      "17/17 - 0s - loss: 3.4254 - val_loss: 3.2412\n",
      "Epoch 133/400\n",
      "17/17 - 0s - loss: 3.4076 - val_loss: 3.2234\n",
      "Epoch 134/400\n",
      "17/17 - 0s - loss: 3.3900 - val_loss: 3.2057\n",
      "Epoch 135/400\n",
      "17/17 - 0s - loss: 3.3725 - val_loss: 3.1882\n",
      "Epoch 136/400\n",
      "17/17 - 0s - loss: 3.3551 - val_loss: 3.1708\n",
      "Epoch 137/400\n",
      "17/17 - 0s - loss: 3.3379 - val_loss: 3.1536\n",
      "Epoch 138/400\n",
      "17/17 - 0s - loss: 3.3209 - val_loss: 3.1366\n",
      "Epoch 139/400\n",
      "17/17 - 0s - loss: 3.3040 - val_loss: 3.1197\n",
      "Epoch 140/400\n",
      "17/17 - 0s - loss: 3.2873 - val_loss: 3.1030\n",
      "Epoch 141/400\n",
      "17/17 - 0s - loss: 3.2707 - val_loss: 3.0865\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 142/400\n",
      "17/17 - 0s - loss: 3.2543 - val_loss: 3.0702\n",
      "Epoch 143/400\n",
      "17/17 - 0s - loss: 3.2381 - val_loss: 3.0540\n",
      "Epoch 144/400\n",
      "17/17 - 0s - loss: 3.2220 - val_loss: 3.0381\n",
      "Epoch 145/400\n",
      "17/17 - 0s - loss: 3.2061 - val_loss: 3.0223\n",
      "Epoch 146/400\n",
      "17/17 - 0s - loss: 3.1904 - val_loss: 3.0066\n",
      "Epoch 147/400\n",
      "17/17 - 0s - loss: 3.1749 - val_loss: 2.9912\n",
      "Epoch 148/400\n",
      "17/17 - 0s - loss: 3.1595 - val_loss: 2.9760\n",
      "Epoch 149/400\n",
      "17/17 - 0s - loss: 3.1444 - val_loss: 2.9609\n",
      "Epoch 150/400\n",
      "17/17 - 0s - loss: 3.1294 - val_loss: 2.9460\n",
      "Epoch 151/400\n",
      "17/17 - 0s - loss: 3.1146 - val_loss: 2.9314\n",
      "Epoch 152/400\n",
      "17/17 - 0s - loss: 3.0999 - val_loss: 2.9169\n",
      "Epoch 153/400\n",
      "17/17 - 0s - loss: 3.0855 - val_loss: 2.9026\n",
      "Epoch 154/400\n",
      "17/17 - 0s - loss: 3.0713 - val_loss: 2.8886\n",
      "Epoch 155/400\n",
      "17/17 - 0s - loss: 3.0572 - val_loss: 2.8747\n",
      "Epoch 156/400\n",
      "17/17 - 0s - loss: 3.0434 - val_loss: 2.8610\n",
      "Epoch 157/400\n",
      "17/17 - 0s - loss: 3.0297 - val_loss: 2.8475\n",
      "Epoch 158/400\n",
      "17/17 - 0s - loss: 3.0162 - val_loss: 2.8342\n",
      "Epoch 159/400\n",
      "17/17 - 0s - loss: 3.0030 - val_loss: 2.8212\n",
      "Epoch 160/400\n",
      "17/17 - 0s - loss: 2.9899 - val_loss: 2.8083\n",
      "Epoch 161/400\n",
      "17/17 - 0s - loss: 2.9770 - val_loss: 2.7957\n",
      "Epoch 162/400\n",
      "17/17 - 0s - loss: 2.9644 - val_loss: 2.7832\n",
      "Epoch 163/400\n",
      "17/17 - 0s - loss: 2.9519 - val_loss: 2.7710\n",
      "Epoch 164/400\n",
      "17/17 - 0s - loss: 2.9396 - val_loss: 2.7590\n",
      "Epoch 165/400\n",
      "17/17 - 0s - loss: 2.9276 - val_loss: 2.7471\n",
      "Epoch 166/400\n",
      "17/17 - 0s - loss: 2.9157 - val_loss: 2.7355\n",
      "Epoch 167/400\n",
      "17/17 - 0s - loss: 2.9041 - val_loss: 2.7241\n",
      "Epoch 168/400\n",
      "17/17 - 0s - loss: 2.8926 - val_loss: 2.7129\n",
      "Epoch 169/400\n",
      "17/17 - 0s - loss: 2.8814 - val_loss: 2.7020\n",
      "Epoch 170/400\n",
      "17/17 - 0s - loss: 2.8703 - val_loss: 2.6912\n",
      "Epoch 171/400\n",
      "17/17 - 0s - loss: 2.8595 - val_loss: 2.6806\n",
      "Epoch 172/400\n",
      "17/17 - 0s - loss: 2.8489 - val_loss: 2.6703\n",
      "Epoch 173/400\n",
      "17/17 - 0s - loss: 2.8384 - val_loss: 2.6601\n",
      "Epoch 174/400\n",
      "17/17 - 0s - loss: 2.8282 - val_loss: 2.6502\n",
      "Epoch 175/400\n",
      "17/17 - 0s - loss: 2.8182 - val_loss: 2.6405\n",
      "Epoch 176/400\n",
      "17/17 - 0s - loss: 2.8084 - val_loss: 2.6310\n",
      "Epoch 177/400\n",
      "17/17 - 0s - loss: 2.7988 - val_loss: 2.6217\n",
      "Epoch 178/400\n",
      "17/17 - 0s - loss: 2.7893 - val_loss: 2.6126\n",
      "Epoch 179/400\n",
      "17/17 - 0s - loss: 2.7801 - val_loss: 2.6037\n",
      "Epoch 180/400\n",
      "17/17 - 0s - loss: 2.7711 - val_loss: 2.5950\n",
      "Epoch 181/400\n",
      "17/17 - 0s - loss: 2.7622 - val_loss: 2.5865\n",
      "Epoch 182/400\n",
      "17/17 - 0s - loss: 2.7536 - val_loss: 2.5782\n",
      "Epoch 183/400\n",
      "17/17 - 0s - loss: 2.7452 - val_loss: 2.5701\n",
      "Epoch 184/400\n",
      "17/17 - 0s - loss: 2.7369 - val_loss: 2.5622\n",
      "Epoch 185/400\n",
      "17/17 - 0s - loss: 2.7288 - val_loss: 2.5544\n",
      "Epoch 186/400\n",
      "17/17 - 0s - loss: 2.7210 - val_loss: 2.5469\n",
      "Epoch 187/400\n",
      "17/17 - 0s - loss: 2.7133 - val_loss: 2.5396\n",
      "Epoch 188/400\n",
      "17/17 - 0s - loss: 2.7058 - val_loss: 2.5325\n",
      "Epoch 189/400\n",
      "17/17 - 0s - loss: 2.6985 - val_loss: 2.5255\n",
      "Epoch 190/400\n",
      "17/17 - 0s - loss: 2.6913 - val_loss: 2.5187\n",
      "Epoch 191/400\n",
      "17/17 - 0s - loss: 2.6843 - val_loss: 2.5121\n",
      "Epoch 192/400\n",
      "17/17 - 0s - loss: 2.6776 - val_loss: 2.5057\n",
      "Epoch 193/400\n",
      "17/17 - 0s - loss: 2.6709 - val_loss: 2.4995\n",
      "Epoch 194/400\n",
      "17/17 - 0s - loss: 2.6645 - val_loss: 2.4934\n",
      "Epoch 195/400\n",
      "17/17 - 0s - loss: 2.6582 - val_loss: 2.4875\n",
      "Epoch 196/400\n",
      "17/17 - 0s - loss: 2.6521 - val_loss: 2.4818\n",
      "Epoch 197/400\n",
      "17/17 - 0s - loss: 2.6461 - val_loss: 2.4763\n",
      "Epoch 198/400\n",
      "17/17 - 0s - loss: 2.6404 - val_loss: 2.4709\n",
      "Epoch 199/400\n",
      "17/17 - 0s - loss: 2.6347 - val_loss: 2.4656\n",
      "Epoch 200/400\n",
      "17/17 - 0s - loss: 2.6292 - val_loss: 2.4606\n",
      "Epoch 201/400\n",
      "17/17 - 0s - loss: 2.6239 - val_loss: 2.4556\n",
      "Epoch 202/400\n",
      "17/17 - 0s - loss: 2.6187 - val_loss: 2.4509\n",
      "Epoch 203/400\n",
      "17/17 - 0s - loss: 2.6137 - val_loss: 2.4462\n",
      "Epoch 204/400\n",
      "17/17 - 0s - loss: 2.6088 - val_loss: 2.4418\n",
      "Epoch 205/400\n",
      "17/17 - 0s - loss: 2.6041 - val_loss: 2.4374\n",
      "Epoch 206/400\n",
      "17/17 - 0s - loss: 2.5995 - val_loss: 2.4332\n",
      "Epoch 207/400\n",
      "17/17 - 0s - loss: 2.5950 - val_loss: 2.4292\n",
      "Epoch 208/400\n",
      "17/17 - 0s - loss: 2.5907 - val_loss: 2.4252\n",
      "Epoch 209/400\n",
      "17/17 - 0s - loss: 2.5865 - val_loss: 2.4214\n",
      "Epoch 210/400\n",
      "17/17 - 0s - loss: 2.5824 - val_loss: 2.4178\n",
      "Epoch 211/400\n",
      "17/17 - 0s - loss: 2.5784 - val_loss: 2.4142\n",
      "Epoch 212/400\n",
      "17/17 - 0s - loss: 2.5746 - val_loss: 2.4108\n",
      "Epoch 213/400\n",
      "17/17 - 0s - loss: 2.5708 - val_loss: 2.4075\n",
      "Epoch 214/400\n",
      "17/17 - 0s - loss: 2.5672 - val_loss: 2.4043\n",
      "Epoch 215/400\n",
      "17/17 - 0s - loss: 2.5638 - val_loss: 2.4012\n",
      "Epoch 216/400\n",
      "17/17 - 0s - loss: 2.5604 - val_loss: 2.3982\n",
      "Epoch 217/400\n",
      "17/17 - 0s - loss: 2.5571 - val_loss: 2.3954\n",
      "Epoch 218/400\n",
      "17/17 - 0s - loss: 2.5539 - val_loss: 2.3926\n",
      "Epoch 219/400\n",
      "17/17 - 0s - loss: 2.5509 - val_loss: 2.3899\n",
      "Epoch 220/400\n",
      "17/17 - 0s - loss: 2.5479 - val_loss: 2.3874\n",
      "Epoch 221/400\n",
      "17/17 - 0s - loss: 2.5450 - val_loss: 2.3849\n",
      "Epoch 222/400\n",
      "17/17 - 0s - loss: 2.5422 - val_loss: 2.3825\n",
      "Epoch 223/400\n",
      "17/17 - 0s - loss: 2.5395 - val_loss: 2.3802\n",
      "Epoch 224/400\n",
      "17/17 - 0s - loss: 2.5369 - val_loss: 2.3780\n",
      "Epoch 225/400\n",
      "17/17 - 0s - loss: 2.5344 - val_loss: 2.3759\n",
      "Epoch 226/400\n",
      "17/17 - 0s - loss: 2.5320 - val_loss: 2.3739\n",
      "Epoch 227/400\n",
      "17/17 - 0s - loss: 2.5296 - val_loss: 2.3719\n",
      "Epoch 228/400\n",
      "17/17 - 0s - loss: 2.5274 - val_loss: 2.3700\n",
      "Epoch 229/400\n",
      "17/17 - 0s - loss: 2.5252 - val_loss: 2.3682\n",
      "Epoch 230/400\n",
      "17/17 - 0s - loss: 2.5230 - val_loss: 2.3665\n",
      "Epoch 231/400\n",
      "17/17 - 0s - loss: 2.5210 - val_loss: 2.3648\n",
      "Epoch 232/400\n",
      "17/17 - 0s - loss: 2.5190 - val_loss: 2.3632\n",
      "Epoch 233/400\n",
      "17/17 - 0s - loss: 2.5171 - val_loss: 2.3616\n",
      "Epoch 234/400\n",
      "17/17 - 0s - loss: 2.5152 - val_loss: 2.3602\n",
      "Epoch 235/400\n",
      "17/17 - 0s - loss: 2.5134 - val_loss: 2.3587\n",
      "Epoch 236/400\n",
      "17/17 - 0s - loss: 2.5117 - val_loss: 2.3574\n",
      "Epoch 237/400\n",
      "17/17 - 0s - loss: 2.5100 - val_loss: 2.3561\n",
      "Epoch 238/400\n",
      "17/17 - 0s - loss: 2.5084 - val_loss: 2.3548\n",
      "Epoch 239/400\n",
      "17/17 - 0s - loss: 2.5069 - val_loss: 2.3536\n",
      "Epoch 240/400\n",
      "17/17 - 0s - loss: 2.5054 - val_loss: 2.3525\n",
      "Epoch 241/400\n",
      "17/17 - 0s - loss: 2.5039 - val_loss: 2.3514\n",
      "Epoch 242/400\n",
      "17/17 - 0s - loss: 2.5025 - val_loss: 2.3503\n",
      "Epoch 243/400\n",
      "17/17 - 0s - loss: 2.5011 - val_loss: 2.3493\n",
      "Epoch 244/400\n",
      "17/17 - 0s - loss: 2.4998 - val_loss: 2.3483\n",
      "Epoch 245/400\n",
      "17/17 - 0s - loss: 2.4986 - val_loss: 2.3474\n",
      "Epoch 246/400\n",
      "17/17 - 0s - loss: 2.4973 - val_loss: 2.3465\n",
      "Epoch 247/400\n",
      "17/17 - 0s - loss: 2.4962 - val_loss: 2.3457\n",
      "Epoch 248/400\n",
      "17/17 - 0s - loss: 2.4950 - val_loss: 2.3448\n",
      "Epoch 249/400\n",
      "17/17 - 0s - loss: 2.4939 - val_loss: 2.3441\n",
      "Epoch 250/400\n",
      "17/17 - 0s - loss: 2.4928 - val_loss: 2.3433\n",
      "Epoch 251/400\n",
      "17/17 - 0s - loss: 2.4918 - val_loss: 2.3426\n",
      "Epoch 252/400\n",
      "17/17 - 0s - loss: 2.4908 - val_loss: 2.3419\n",
      "Epoch 253/400\n",
      "17/17 - 0s - loss: 2.4898 - val_loss: 2.3413\n",
      "Epoch 254/400\n",
      "17/17 - 0s - loss: 2.4889 - val_loss: 2.3406\n",
      "Epoch 255/400\n",
      "17/17 - 0s - loss: 2.4880 - val_loss: 2.3400\n",
      "Epoch 256/400\n",
      "17/17 - 0s - loss: 2.4871 - val_loss: 2.3395\n",
      "Epoch 257/400\n",
      "17/17 - 0s - loss: 2.4863 - val_loss: 2.3389\n",
      "Epoch 258/400\n",
      "17/17 - 0s - loss: 2.4854 - val_loss: 2.3384\n",
      "Epoch 259/400\n",
      "17/17 - 0s - loss: 2.4846 - val_loss: 2.3379\n",
      "Epoch 260/400\n",
      "17/17 - 0s - loss: 2.4839 - val_loss: 2.3374\n",
      "Epoch 261/400\n",
      "17/17 - 0s - loss: 2.4831 - val_loss: 2.3369\n",
      "Epoch 262/400\n",
      "17/17 - 0s - loss: 2.4824 - val_loss: 2.3365\n",
      "Epoch 263/400\n",
      "17/17 - 0s - loss: 2.4817 - val_loss: 2.3361\n",
      "Epoch 264/400\n",
      "17/17 - 0s - loss: 2.4810 - val_loss: 2.3356\n",
      "Epoch 265/400\n",
      "17/17 - 0s - loss: 2.4804 - val_loss: 2.3353\n",
      "Epoch 266/400\n",
      "17/17 - 0s - loss: 2.4797 - val_loss: 2.3349\n",
      "Epoch 267/400\n",
      "17/17 - 0s - loss: 2.4791 - val_loss: 2.3345\n",
      "Epoch 268/400\n",
      "17/17 - 0s - loss: 2.4785 - val_loss: 2.3342\n",
      "Epoch 269/400\n",
      "17/17 - 0s - loss: 2.4779 - val_loss: 2.3339\n",
      "Epoch 270/400\n",
      "17/17 - 0s - loss: 2.4773 - val_loss: 2.3335\n",
      "Epoch 271/400\n",
      "17/17 - 0s - loss: 2.4768 - val_loss: 2.3332\n",
      "Epoch 272/400\n",
      "17/17 - 0s - loss: 2.4762 - val_loss: 2.3329\n",
      "Epoch 273/400\n",
      "17/17 - 0s - loss: 2.4757 - val_loss: 2.3327\n",
      "Epoch 274/400\n",
      "17/17 - 0s - loss: 2.4752 - val_loss: 2.3324\n",
      "Epoch 275/400\n",
      "17/17 - 0s - loss: 2.4747 - val_loss: 2.3321\n",
      "Epoch 276/400\n",
      "17/17 - 0s - loss: 2.4742 - val_loss: 2.3319\n",
      "Epoch 277/400\n",
      "17/17 - 0s - loss: 2.4737 - val_loss: 2.3316\n",
      "Epoch 278/400\n",
      "17/17 - 0s - loss: 2.4733 - val_loss: 2.3314\n",
      "Epoch 279/400\n",
      "17/17 - 0s - loss: 2.4728 - val_loss: 2.3312\n",
      "Epoch 280/400\n",
      "17/17 - 0s - loss: 2.4724 - val_loss: 2.3310\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 281/400\n",
      "17/17 - 0s - loss: 2.4719 - val_loss: 2.3308\n",
      "Epoch 282/400\n",
      "17/17 - 0s - loss: 2.4715 - val_loss: 2.3306\n",
      "Epoch 283/400\n",
      "17/17 - 0s - loss: 2.4711 - val_loss: 2.3304\n",
      "Epoch 284/400\n",
      "17/17 - 0s - loss: 2.4707 - val_loss: 2.3302\n",
      "Epoch 285/400\n",
      "17/17 - 0s - loss: 2.4703 - val_loss: 2.3300\n",
      "Epoch 286/400\n",
      "17/17 - 0s - loss: 2.4699 - val_loss: 2.3298\n",
      "Epoch 287/400\n",
      "17/17 - 0s - loss: 2.4695 - val_loss: 2.3297\n",
      "Epoch 288/400\n",
      "17/17 - 0s - loss: 2.4691 - val_loss: 2.3295\n",
      "Epoch 289/400\n",
      "17/17 - 0s - loss: 2.4688 - val_loss: 2.3293\n",
      "Epoch 290/400\n",
      "17/17 - 0s - loss: 2.4684 - val_loss: 2.3292\n",
      "Epoch 291/400\n",
      "17/17 - 0s - loss: 2.4681 - val_loss: 2.3290\n",
      "Epoch 292/400\n",
      "17/17 - 0s - loss: 2.4677 - val_loss: 2.3289\n",
      "Epoch 293/400\n",
      "17/17 - 0s - loss: 2.4674 - val_loss: 2.3288\n",
      "Epoch 294/400\n",
      "17/17 - 0s - loss: 2.4670 - val_loss: 2.3286\n",
      "Epoch 295/400\n",
      "17/17 - 0s - loss: 2.4667 - val_loss: 2.3285\n",
      "Epoch 296/400\n",
      "17/17 - 0s - loss: 2.4664 - val_loss: 2.3283\n",
      "Epoch 297/400\n",
      "17/17 - 0s - loss: 2.4661 - val_loss: 2.3282\n",
      "Epoch 298/400\n",
      "17/17 - 0s - loss: 2.4658 - val_loss: 2.3281\n",
      "Epoch 299/400\n",
      "17/17 - 0s - loss: 2.4655 - val_loss: 2.3280\n",
      "Epoch 300/400\n",
      "17/17 - 0s - loss: 2.4651 - val_loss: 2.3278\n",
      "Epoch 301/400\n",
      "17/17 - 0s - loss: 2.4648 - val_loss: 2.3277\n",
      "Epoch 302/400\n",
      "17/17 - 0s - loss: 2.4645 - val_loss: 2.3276\n",
      "Epoch 303/400\n",
      "17/17 - 0s - loss: 2.4643 - val_loss: 2.3275\n",
      "Epoch 304/400\n",
      "17/17 - 0s - loss: 2.4640 - val_loss: 2.3274\n",
      "Epoch 305/400\n",
      "17/17 - 0s - loss: 2.4637 - val_loss: 2.3273\n",
      "Epoch 306/400\n",
      "17/17 - 0s - loss: 2.4634 - val_loss: 2.3272\n",
      "Epoch 307/400\n",
      "17/17 - 0s - loss: 2.4631 - val_loss: 2.3271\n",
      "Epoch 308/400\n",
      "17/17 - 0s - loss: 2.4628 - val_loss: 2.3270\n",
      "Epoch 309/400\n",
      "17/17 - 0s - loss: 2.4626 - val_loss: 2.3268\n",
      "Epoch 310/400\n",
      "17/17 - 0s - loss: 2.4623 - val_loss: 2.3267\n",
      "Epoch 311/400\n",
      "17/17 - 0s - loss: 2.4620 - val_loss: 2.3266\n",
      "Epoch 312/400\n",
      "17/17 - 0s - loss: 2.4618 - val_loss: 2.3265\n",
      "Epoch 313/400\n",
      "17/17 - 0s - loss: 2.4615 - val_loss: 2.3264\n",
      "Epoch 314/400\n",
      "17/17 - 0s - loss: 2.4612 - val_loss: 2.3263\n",
      "Epoch 315/400\n",
      "17/17 - 0s - loss: 2.4610 - val_loss: 2.3262\n",
      "Epoch 316/400\n",
      "17/17 - 0s - loss: 2.4607 - val_loss: 2.3262\n",
      "Epoch 317/400\n",
      "17/17 - 0s - loss: 2.4605 - val_loss: 2.3261\n",
      "Epoch 318/400\n",
      "17/17 - 0s - loss: 2.4602 - val_loss: 2.3260\n",
      "Epoch 319/400\n",
      "17/17 - 0s - loss: 2.4600 - val_loss: 2.3259\n",
      "Epoch 320/400\n",
      "17/17 - 0s - loss: 2.4597 - val_loss: 2.3258\n",
      "Epoch 321/400\n",
      "17/17 - 0s - loss: 2.4595 - val_loss: 2.3257\n",
      "Epoch 322/400\n",
      "17/17 - 0s - loss: 2.4592 - val_loss: 2.3256\n",
      "Epoch 323/400\n",
      "17/17 - 0s - loss: 2.4590 - val_loss: 2.3255\n",
      "Epoch 324/400\n",
      "17/17 - 0s - loss: 2.4587 - val_loss: 2.3254\n",
      "Epoch 325/400\n",
      "17/17 - 0s - loss: 2.4585 - val_loss: 2.3253\n",
      "Epoch 326/400\n",
      "17/17 - 0s - loss: 2.4583 - val_loss: 2.3252\n",
      "Epoch 327/400\n",
      "17/17 - 0s - loss: 2.4580 - val_loss: 2.3251\n",
      "Epoch 328/400\n",
      "17/17 - 0s - loss: 2.4578 - val_loss: 2.3250\n",
      "Epoch 329/400\n",
      "17/17 - 0s - loss: 2.4575 - val_loss: 2.3249\n",
      "Epoch 330/400\n",
      "17/17 - 0s - loss: 2.4573 - val_loss: 2.3249\n",
      "Epoch 331/400\n",
      "17/17 - 0s - loss: 2.4571 - val_loss: 2.3248\n",
      "Epoch 332/400\n",
      "17/17 - 0s - loss: 2.4568 - val_loss: 2.3247\n",
      "Epoch 333/400\n",
      "17/17 - 0s - loss: 2.4566 - val_loss: 2.3246\n",
      "Epoch 334/400\n",
      "17/17 - 0s - loss: 2.4564 - val_loss: 2.3245\n",
      "Epoch 335/400\n",
      "17/17 - 0s - loss: 2.4562 - val_loss: 2.3244\n",
      "Epoch 336/400\n",
      "17/17 - 0s - loss: 2.4559 - val_loss: 2.3243\n",
      "Epoch 337/400\n",
      "17/17 - 0s - loss: 2.4557 - val_loss: 2.3242\n",
      "Epoch 338/400\n",
      "17/17 - 0s - loss: 2.4555 - val_loss: 2.3241\n",
      "Epoch 339/400\n",
      "17/17 - 0s - loss: 2.4552 - val_loss: 2.3241\n",
      "Epoch 340/400\n",
      "17/17 - 0s - loss: 2.4550 - val_loss: 2.3240\n",
      "Epoch 341/400\n",
      "17/17 - 0s - loss: 2.4548 - val_loss: 2.3239\n",
      "Epoch 342/400\n",
      "17/17 - 0s - loss: 2.4546 - val_loss: 2.3238\n",
      "Epoch 343/400\n",
      "17/17 - 0s - loss: 2.4543 - val_loss: 2.3237\n",
      "Epoch 344/400\n",
      "17/17 - 0s - loss: 2.4541 - val_loss: 2.3236\n",
      "Epoch 345/400\n",
      "17/17 - 0s - loss: 2.4539 - val_loss: 2.3235\n",
      "Epoch 346/400\n",
      "17/17 - 0s - loss: 2.4537 - val_loss: 2.3234\n",
      "Epoch 347/400\n",
      "17/17 - 0s - loss: 2.4535 - val_loss: 2.3234\n",
      "Epoch 348/400\n",
      "17/17 - 0s - loss: 2.4532 - val_loss: 2.3233\n",
      "Epoch 349/400\n",
      "17/17 - 0s - loss: 2.4530 - val_loss: 2.3232\n",
      "Epoch 350/400\n",
      "17/17 - 0s - loss: 2.4528 - val_loss: 2.3231\n",
      "Epoch 351/400\n",
      "17/17 - 0s - loss: 2.4526 - val_loss: 2.3230\n",
      "Epoch 352/400\n",
      "17/17 - 0s - loss: 2.4524 - val_loss: 2.3229\n",
      "Epoch 353/400\n",
      "17/17 - 0s - loss: 2.4522 - val_loss: 2.3228\n",
      "Epoch 354/400\n",
      "17/17 - 0s - loss: 2.4519 - val_loss: 2.3227\n",
      "Epoch 355/400\n",
      "17/17 - 0s - loss: 2.4517 - val_loss: 2.3227\n",
      "Epoch 356/400\n",
      "17/17 - 0s - loss: 2.4515 - val_loss: 2.3226\n",
      "Epoch 357/400\n",
      "17/17 - 0s - loss: 2.4513 - val_loss: 2.3225\n",
      "Epoch 358/400\n",
      "17/17 - 0s - loss: 2.4511 - val_loss: 2.3224\n",
      "Epoch 359/400\n",
      "17/17 - 0s - loss: 2.4509 - val_loss: 2.3223\n",
      "Epoch 360/400\n",
      "17/17 - 0s - loss: 2.4507 - val_loss: 2.3222\n",
      "Epoch 361/400\n",
      "17/17 - 0s - loss: 2.4505 - val_loss: 2.3221\n",
      "Epoch 362/400\n",
      "17/17 - 0s - loss: 2.4502 - val_loss: 2.3221\n",
      "Epoch 363/400\n",
      "17/17 - 0s - loss: 2.4500 - val_loss: 2.3220\n",
      "Epoch 364/400\n",
      "17/17 - 0s - loss: 2.4498 - val_loss: 2.3219\n",
      "Epoch 365/400\n",
      "17/17 - 0s - loss: 2.4496 - val_loss: 2.3218\n",
      "Epoch 366/400\n",
      "17/17 - 0s - loss: 2.4494 - val_loss: 2.3217\n",
      "Epoch 367/400\n",
      "17/17 - 0s - loss: 2.4492 - val_loss: 2.3216\n",
      "Epoch 368/400\n",
      "17/17 - 0s - loss: 2.4490 - val_loss: 2.3215\n",
      "Epoch 369/400\n",
      "17/17 - 0s - loss: 2.4488 - val_loss: 2.3214\n",
      "Epoch 370/400\n",
      "17/17 - 0s - loss: 2.4486 - val_loss: 2.3214\n",
      "Epoch 371/400\n",
      "17/17 - 0s - loss: 2.4484 - val_loss: 2.3213\n",
      "Epoch 372/400\n",
      "17/17 - 0s - loss: 2.4482 - val_loss: 2.3212\n",
      "Epoch 373/400\n",
      "17/17 - 0s - loss: 2.4479 - val_loss: 2.3211\n",
      "Epoch 374/400\n",
      "17/17 - 0s - loss: 2.4477 - val_loss: 2.3210\n",
      "Epoch 375/400\n",
      "17/17 - 0s - loss: 2.4475 - val_loss: 2.3209\n",
      "Epoch 376/400\n",
      "17/17 - 0s - loss: 2.4473 - val_loss: 2.3208\n",
      "Epoch 377/400\n",
      "17/17 - 0s - loss: 2.4471 - val_loss: 2.3208\n",
      "Epoch 378/400\n",
      "17/17 - 0s - loss: 2.4469 - val_loss: 2.3207\n",
      "Epoch 379/400\n",
      "17/17 - 0s - loss: 2.4467 - val_loss: 2.3206\n",
      "Epoch 380/400\n",
      "17/17 - 0s - loss: 2.4465 - val_loss: 2.3205\n",
      "Epoch 381/400\n",
      "17/17 - 0s - loss: 2.4463 - val_loss: 2.3204\n",
      "Epoch 382/400\n",
      "17/17 - 0s - loss: 2.4461 - val_loss: 2.3203\n",
      "Epoch 383/400\n",
      "17/17 - 0s - loss: 2.4459 - val_loss: 2.3202\n",
      "Epoch 384/400\n",
      "17/17 - 0s - loss: 2.4457 - val_loss: 2.3202\n",
      "Epoch 385/400\n",
      "17/17 - 0s - loss: 2.4455 - val_loss: 2.3201\n",
      "Epoch 386/400\n",
      "17/17 - 0s - loss: 2.4453 - val_loss: 2.3200\n",
      "Epoch 387/400\n",
      "17/17 - 0s - loss: 2.4451 - val_loss: 2.3199\n",
      "Epoch 388/400\n",
      "17/17 - 0s - loss: 2.4449 - val_loss: 2.3198\n",
      "Epoch 389/400\n",
      "17/17 - 0s - loss: 2.4447 - val_loss: 2.3197\n",
      "Epoch 390/400\n",
      "17/17 - 0s - loss: 2.4445 - val_loss: 2.3197\n",
      "Epoch 391/400\n",
      "17/17 - 0s - loss: 2.4443 - val_loss: 2.3196\n",
      "Epoch 392/400\n",
      "17/17 - 0s - loss: 2.4441 - val_loss: 2.3195\n",
      "Epoch 393/400\n",
      "17/17 - 0s - loss: 2.4439 - val_loss: 2.3194\n",
      "Epoch 394/400\n",
      "17/17 - 0s - loss: 2.4437 - val_loss: 2.3193\n",
      "Epoch 395/400\n",
      "17/17 - 0s - loss: 2.4435 - val_loss: 2.3192\n",
      "Epoch 396/400\n",
      "17/17 - 0s - loss: 2.4433 - val_loss: 2.3192\n",
      "Epoch 397/400\n",
      "17/17 - 0s - loss: 2.4431 - val_loss: 2.3191\n",
      "Epoch 398/400\n",
      "17/17 - 0s - loss: 2.4429 - val_loss: 2.3190\n",
      "Epoch 399/400\n",
      "17/17 - 0s - loss: 2.4427 - val_loss: 2.3189\n",
      "Epoch 400/400\n",
      "17/17 - 0s - loss: 2.4425 - val_loss: 2.3188\n"
     ]
    }
   ],
   "source": [
    "stock = \"INTC\"\n",
    "\n",
    "\n",
    "sd = get_stock_data(standardized_data_with_target,stock)\n",
    "X,y  = split_stock_data(sd)\n",
    "\n",
    "X_train, X_test, y_train, y_test = sk.model_selection.train_test_split(X,y,test_size=0.125)\n",
    "\n",
    "X_train,y_train = create_dataset(X_train, y_train, time_steps=time_steps)\n",
    "X_test,y_test = create_dataset(X_test, y_test, time_steps=time_steps)\n",
    "history = model.fit(X_train, y_train, epochs=400, batch_size=10, verbose=2,validation_split=0.125,shuffle = False,callbacks=[EarlyStopping(monitor='val_loss',patience=40, min_delta=0.0001)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAEWCAYAAABsY4yMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXwU9f3H8ddnN/dBgJAgEuRUEJEbFA+0HijgUS+0iPWq2tZW+6snba1Xa621am3rjUc98L5BxQtvuU85BBQhXOFKCEnIsfv9/TELBkhCAtlMsnk/H4997OzM7Mxn5xHeO3x35vs15xwiIhJ7An4XICIi0aGAFxGJUQp4EZEYpYAXEYlRCngRkRilgBcRiVEKeBHAzJ40s7/Uct3lZnbCvm5HJNoU8CIiMUoBLyISoxTw0mREmkauM7O5ZlZkZuPMrK2ZvWNmhWb2gZm1qrT+aWb2jZnlm9lkMzu40rJ+ZjYz8r4XgKRd9nWKmc2OvPdLM+u9lzVfZmZLzWyTmb1pZvtH5puZ3WtmeWZWEPlMvSLLRpjZgkhtq8zs2r06YNLsKeClqTkLOBE4CDgVeAf4A9AG7+/5KgAzOwgYD/wOyAImAm+ZWYKZJQCvA08DrYGXItsl8t7+wOPAFUAm8DDwppkl1qVQMzsO+BswCmgH/AA8H1k8DBga+RwtgXOBjZFl44ArnHPpQC/go7rsV2Q7Bbw0Nf92zq1zzq0CPgOmOOdmOedKgdeAfpH1zgUmOOfed86VA3cDycARwOFAPHCfc67cOfcyMK3SPi4DHnbOTXHOhZxzTwGlkffVxfnA4865mZH6xgJDzKwTUA6kAz0Ac84tdM6tibyvHOhpZi2cc5udczPruF8RQAEvTc+6StMlVbxOi0zvj3fGDIBzLgysBNpHlq1yO/e090Ol6Y7ANZHmmXwzywc6RN5XF7vWsBXvLL29c+4j4D/Af4F1ZvaImbWIrHoWMAL4wcw+MbMhddyvCKCAl9i1Gi+oAa/NGy+kVwFrgPaRedsdUGl6JfBX51zLSo8U59z4fawhFa/JZxWAc+5+59wA4BC8pprrIvOnOedOB7LxmpJerON+RQAFvMSuF4GRZna8mcUD1+A1s3wJfAVUAFeZWZyZnQkMrvTeR4FfmtlhkR9DU81spJml17GG54CLzaxvpP3+DrwmpeVmNiiy/XigCNgGhCK/EZxvZhmRpqUtQGgfjoM0Ywp4iUnOucXAGODfwAa8H2RPdc6VOefKgDOBi4DNeO31r1Z673S8dvj/RJYvjaxb1xo+BG4CXsH7X0NX4LzI4hZ4XySb8ZpxNuL9TgBwAbDczLYAv4x8DpE6Mw34ISISm3QGLyISoxTwIiIxSgEvIhKjFPAiIjEqzu8CKmvTpo3r1KmT32WIiDQZM2bM2OCcy6pqWaMK+E6dOjF9+nS/yxARaTLM7IfqlqmJRkQkRingRURilAJeRCRGNao2+KqUl5eTm5vLtm3b/C4lqpKSksjJySE+Pt7vUkQkRjT6gM/NzSU9PZ1OnTqxc+d/scM5x8aNG8nNzaVz585+lyMiMaLRN9Fs27aNzMzMmA13ADMjMzMz5v+XIiINq9EHPBDT4b5dc/iMItKwmkTA18iFoXAdlBX5XYmISKMSAwHvoGg95K/0putZfn4+DzzwQJ3fN2LECPLz8+u9HhGR2mr6AR8IQkYOVJR4QV/Pqgv4UKjmQXYmTpxIy5Yt670eEZHaavRX0dRKUgYktoDCNZDUEuIS6m3TN954I8uWLaNv377Ex8eTlpZGu3btmD17NgsWLOCnP/0pK1euZNu2bVx99dVcfvnlwI/dLmzdupXhw4dz1FFH8eWXX9K+fXveeOMNkpOT661GEZGqNKmAv/Wtb1iwekvVC10YyoshsAnikmq9zZ77t+DmUw+pdvmdd97J/PnzmT17NpMnT2bkyJHMnz9/x+WMjz/+OK1bt6akpIRBgwZx1llnkZmZudM2lixZwvjx43n00UcZNWoUr7zyCmPGaBQ2EYmuJhXwNbIABBMgVAbhkNd0EwWDBw/e6Vr1+++/n9deew2AlStXsmTJkt0CvnPnzvTt2xeAAQMGsHz58qjUJiJSWZMK+OrOtCtCYQJmBMzB+kXej61ZB0Og/n9iSE1N3TE9efJkPvjgA7766itSUlI49thjq7yWPTExccd0MBikpKSk3usSEdlVk/+RtSIUZkneVtYVbvPO4jM6eGfxW9fWy/bT09MpLCyscllBQQGtWrUiJSWFRYsW8fXXX9fLPkVE6kOTOoOvSlwwQHpSHOsLS2mRFE9qYjokt4KteZDcGuJr3x5flczMTI488kh69epFcnIybdu23bHs5JNP5qGHHqJ37950796dww8/fF8/johIvTEXhWvH99bAgQPdrgN+LFy4kIMPPrjG94XCjiV53ln2gdnpBF0F5C2E+GTI7AZN5C7R2nxWEZHKzGyGc25gVcuafBMNQDBgdGiVQllFmDUFJRCMhxbtoGwrlGz2uzwREV/ERMADpCbGkZWeyKaiMraUlENKG4hPgS2rIFzhd3kiIg0uZgIeoG2LJJLig+Tml1ARdt4PruEK2LLG79JERBpcTAV8wIwOrZIJhR2r8ktw8cmQmgXFG9QZmYg0OzEV8ADJCXG0TU+koKScgpJySG8HgXgoiE5nZCIijVXMBTxAVnoiKQlxrMovoTxskNEeykugaIPfpYmINJiYDHiLNNU4Bys3F+OSWkJiutcZWai8Ttva2+6CAe677z6Ki4v36r0iIvsqJgMeIDE+SLuMJLaWVrCpqMzrUtiFvatq6kABLyJNVZO/k7UmrVMTKCgpZ03BNtIS00hMy4at67xLKBPTarWNyt0Fn3jiiWRnZ/Piiy9SWlrKGWecwa233kpRURGjRo0iNzeXUCjETTfdxLp161i9ejU/+clPaNOmDR9//HGUP62IyM6aVsC/cyOsnVfr1Q3o5Bwl5SHCZrj4AFZW7N3ZGp/srbHfoTD8zmq3Ubm74EmTJvHyyy8zdepUnHOcdtppfPrpp6xfv57999+fCRMmAF4fNRkZGdxzzz18/PHHtGnTZh8/uIhI3cVsE812ATMS4wKEwo7ykPMGA3EhCNetLR5g0qRJTJo0iX79+tG/f38WLVrEkiVLOPTQQ/nggw+44YYb+Oyzz8jIyIjCJxERqZumdQZfw5l2TYLOsXFTMVu2VdAtK5XkLd97V9Vk94Rg7Q+Bc46xY8dyxRVX7LZsxowZTJw4kbFjxzJs2DD+/Oc/71WtIiL1JebP4MG7qqZ9y2SCAWPl5hLCLdp7Z/GFe77DtXJ3wSeddBKPP/44W7duBWDVqlXk5eWxevVqUlJSGDNmDNdeey0zZ87c7b0iIg2taZ3B74O4YICclsks31jEupI42qVmeYN0p2RCQkq176vcXfDw4cMZPXo0Q4YMASAtLY1nnnmGpUuXct111xEIBIiPj+fBBx8E4PLLL2f48OG0a9dOP7KKSIOLie6C6yJ3czGbisro1iaZlPxvIS4RMg9sFF0Kq7tgEamrmO8uuC7aZSSTEAywIr+UcFo7r48adSksIjGo2QV8MGDktI70HV+eEulSeLU3ULeISAyJasCbWUsze9nMFpnZQjMbsjfbqe9mpLRI3/Ebi8ooSt7Pu2SynsZw3VuNqalMRGJDtM/g/wW865zrAfQBFtZ1A0lJSWzcuLHeA7Btutd3/IpCI5zUCrauh4pt9bqP2nLOsXHjRpKS9m38WBGRyqJ2FY2ZtQCGAhcBOOfKgLK6bicnJ4fc3FzWr19fvwUCZRVh1heWsjneaBXaAKu3eP3H+yApKYmcnBxf9i0isSmal0l2AdYDT5hZH2AGcLVzbqeRN8zscuBygAMOOGC3jcTHx9O5c+eoFfmfj5Zw95vfMrH/dHouuAd+/iZ0OSZq+xMRaSjRbKKJA/oDDzrn+gFFwI27ruSce8Q5N9A5NzArq+HPnn95TFf6dmjJhQsGEGrRAd77g35wFZGYEM2AzwVynXNTIq9fxgv8RiUuGOCfo/pQGAryUMKFsG4+zHrG77JERPZZ1ALeObcWWGlm3SOzjgcWRGt/+6JrVhpjhx/MP3IPZn3r/vDR7bBti99liYjsk2hfRfNb4Fkzmwv0Be6I8v722gWHd2Rw50x+u+lsrwuDz+/xuyQRkX0S1YB3zs2OtK/3ds791DnXaG8ZDQSMu87qzexQF75MOxH31QOwebnfZYmI7LVmdydrTTq1SeXaYd35vw2nEyIA79/sd0kiIntNAb+Li4/sTLsOXXg0fCoseB1++MrvkkRE9ooCfhfBgPGPs3vzUNkINse1gffGQjjsd1kiInWmgK/CgW3TufyEQ7m1eBSsngXzXvS7JBGROlPAV+PyoV1Y2vZkvqEb4fdv9roVFhFpQhTw1YgPBvj7OX25tXwMga1r4Yv7/S5JRKROFPA1OGT/DA4/ZgRvhw4n9Pl9ULDK75JERGpNAb8HVx7XjRdaXkpFKETZ+7f5XY6ISK0p4PcgMS7INaOG8WTFySTMfx5Wz/a7JBGRWlHA10LfDi0pGnw1G106BW9cDxp9SUSaAAV8Lf16eH+eThpNxroplH7zlt/liIjskQK+lpLigww55xqWhNuz9a0/QEWdB6cSEWlQCvg6OKxbW77q9jsyS1ey8v3/+F2OiEiNFPB1dMY5FzHVepMx9R5KCzf6XY6ISLUU8HWUnpwAJ/2VtPBW5o3/k9/liIhUSwG/FwYfPpSpLUfQe9ULLF00x+9yRESqpIDfS91H30mFxbPu1bFUhNTbpIg0Pgr4vdSq7QGsPPgyjiz7gncmvOp3OSIiu1HA74ODzhjL5mAbOs64g+XrC/0uR0RkJwr4fWAJqQROvIXetoy3nr2fcFh3uIpI46GA30cZg89nU4uenLl5HC99vcTvckREdlDA76tAgFZn3EV728ja9/7JmoISvysSEQEU8PXCOh9NcZeT+QWvc9dLn+LUGZmINAIK+HqSMvIOkgMVDFr+EG/OWe13OSIiCvh6k9kVBv+Cc+Mm88yb77Jxa6nfFYlIM6eAr0eBY26AxHR+W/Ekt729wO9yRKSZU8DXp5TWBI+9kaGBueTPfYcPF67zuyIRacYU8PVt0C9wrbpwa9J4/vzqHLZsK/e7IhFpphTw9S0uARt2G53CKzi2+F3ufGeR3xWJSDOlgI+GHqfAAUfwh+RXeXPKIr5apn7jRaThKeCjwQxO+iupFZu5Mf0dxr46l5KykN9ViUgzo4CPlvb9ofd5jA69RfnGH7j3g2/9rkhEmhkFfDQdfxOBQID/7vc2j332HXNW5vtdkYg0Iwr4aMrIgSN+S9/89zkmdQU3vDKXsgoNDiIiDUMBH21HXg2p2dzb8kUWrd3CQ58s87siEWkmFPDRlpgOx/2Jlhtm8ucuS/j3R0v4dp0GBxGR6FPAN4R+YyD7EC4sepxWCY7rX55LSIODiEiURTXgzWy5mc0zs9lmNj2a+2rUAkE46S8EC1bweM9ZzF6Zz5NfLve7KhGJcQ1xBv8T51xf59zABthX49X1ODhwGIcsfZjTDkzk7vcWs2Jjsd9ViUgMUxNNQzrxdqysiL9lTiQYMMa+NleDg4hI1EQ74B0wycxmmNnlVa1gZpeb2XQzm75+/fool+Oz7B4w4CJS5z7FHUMT+WLpRl6cvtLvqkQkRkU74I90zvUHhgNXmtnQXVdwzj3inBvonBuYlZUV5XIagWPHQlwyp657iMM6t+YvExaybss2v6sSkRgU1YB3zq2OPOcBrwGDo7m/JiEtC4Zeg337DvcdtoWyijB/en2+mmpEpN5FLeDNLNXM0rdPA8OA+dHaX5Ny2K8g4wDafX07157YlfcXrGPCvDV+VyUiMSaaZ/Btgc/NbA4wFZjgnHs3ivtrOuKT4ISbYe08LkmfSu+cDG5+4xs2F5X5XZmIxJCoBbxz7jvnXJ/I4xDn3F+jta8mqddZkDOI4Ee3c9dp3SgoKed2jeMqIvVIl0n6xQyG/RW2rqXHd0/y62O78uqsVXy8OM/vykQkRijg/XTAYXDIGfDFv7hyUCoHZqfxx1fnUahxXEWkHijg/XbCLRCuIPGTv/H3s3uzZss27np3sd9ViUgMUMD7rVUnOOyXMPtZ+sev4OIjOvP01z8w9ftNflcmIk2cAr4xOPoaSMmEiddx7bBu5LRK5oZX5rKtXOO4isjeU8A3Bskt4cTbYOUUUha+zJ1n9ub7DUXc98ESvysTkSZMAd9Y9PkZ5AyGSTdxVE4c5w7swKOffce83AK/KxORJkoB31gEAjDybijZBB/fwR9GHkxmagLXvzKX8pDGcRWRulPANybt+sDAS2Hao2QULOL2n/Zi4ZotPPCxxnEVkbpTwDc2x/0RklvDhGs5qWdbTuuzP//+aImaakSkzhTwjU1yK+/a+JVfw5znuf30XrRJS+R3L8zSVTUiUicK+Mao7/mQMwjev4kMK+If5/Rm2foi/v7uIr8rE5EmpFYBb2ZXm1kL84wzs5lmNizaxTVbgQCMuBuKNsDkv3H0gVlcOKQjT3yxnC+WbvC7OhFpImp7Bn+Jc24LXp/uWcDFwJ1Rq0pg/74w8BKY+gisnceNww+mS1Yq1740h4IS9VUjIntW24C3yPMI4Ann3JxK8yRajvuT1yb/9v+RHGfcO6oveYWl3PyGxk0RkT2rbcDPMLNJeAH/XmSkJl2cHW0preGkOyB3Gsx4nD4dWvKbn3Tj9dmrmTBXI0CJSM1qG/CXAjcCg5xzxUA8XjONRFvvc6HzMfDBrVC4lt8c143eORn88fV55GmwbhGpQW0Dfgiw2DmXb2ZjgD8BujC7IZjBKfdCRSm8eyPxwQD3jOpLSVmI61+Zq8G6RaRatQ34B4FiM+sDXA/8APwvalXJzjK7wtDr4JvX4NtJdMtOY+zwHkxevJ6nv/7B7+pEpJGqbcBXOO9U8XTgX865fwHp0StLdnPk1dCmO0y4BsqK+PmQThxzUBZ/nbCQxWsL/a5ORBqh2gZ8oZmNBS4AJphZEK8dXhpKXAKceh8UrIDJdxIIGHef04f0pDiuGq+7XEVkd7UN+HOBUrzr4dcC7YF/RK0qqVrHI6D/z+Gr/8LaeWSlJ3L3OX1YvK6QOyYu9Ls6EWlkahXwkVB/Fsgws1OAbc45tcH74YRbvWvj37wKQhUc2z2bS4/qzP+++oEPFqzzuzoRaURq21XBKGAqcA4wCphiZmdHszCpRkprGP53WD0Tvn4AgOtP7k7Pdi247uU5rNOlkyISUdsmmj/iXQN/oXPu58Bg4KbolSU16nUWdB8JH/8VNi4jMS7I/T/rx7byML9/cTbhsC6dFJHaB3zAOZdX6fXGOrxX6psZjPwnxCXCG7+BcJhu2WncfGpPvli6kUc++87vCkWkEahtSL9rZu+Z2UVmdhEwAZgYvbJkj1q0g5P+Biu+hOnjADh3UAdGHLofd7+3mDkr830uUET8VtsfWa8DHgF6A32AR5xzN0SzMKmFvqOh6/Hw/s2w+QfMjL+d0Zvs9ESufn4WW0sr/K5QRHxU62YW59wrzrnfO+f+zzn3WjSLkloy866NN4O3rgLnyEiJ577z+rFiUzFjX52nrgxEmrEaA97MCs1sSxWPQjPb0lBFSg1aHgAn3grfTYZZTwMwuHNrrhnWnbfmrObZKSv8rU9EfFNjwDvn0p1zLap4pDvnWjRUkbIHAy6BjkfBe3+CglUA/OqYrhxzUBa3vb2A+avUL5xIc6QrYWJBIACn/xvCFfDGryEcJhAw7j23L61TErjyuZls2aZRoESaGwV8rGjdBU76i9dUE7mqpnVqAv8Z3Y/czSXcqK6FRZodBXwsGXAxdDsBJt0EG5YCMLBTa647qTsT563lf1+pa2GR5kQBH0vM4LT/eDdAvXYFhLzLJC8/ugvH9cjmLxMWMDdX18eLNBcK+FjToh2ccg+smg5f3AtAIGD885w+ZKUlcuVzMykoUXu8SHOggI9Fvc7yHpPvhDVzAGiVmsB/zu/PmvxtXPfSHLXHizQDUQ94Mwua2Swzezva+5JKRtwNKW3g1Sug3Othsv8BrbhxeA8mLVjHw5+qvxqRWNcQZ/BXAxqNoqGltIbT/wvrF8KHt+6YfelRnRl5aDvuencRXyzd4GOBIhJtUQ14M8sBRgKPRXM/Uo0DT4DBl3v9xi/5AAAz466ze9M1K43fPDeT3M3FPhcpItES7TP4+4DrgXB1K5jZ5WY23cymr1+/PsrlNEMn3g7Zh8Drv4StXo/PqYlxPHzBACpCjl89M1PjuYrEqKgFfGRovzzn3Iya1nPOPeKcG+icG5iVlRWtcpqv+CQ4+3EoLYTXfglh77u2S1Ya95zbl3mrCrjp9fn60VUkBkXzDP5I4DQzWw48DxxnZs9EcX9SnewecNIdsOzDHcP8AZzYsy1XHdeNl2bk8txUdUomEmuiFvDOubHOuRznXCfgPOAj59yYaO1P9mDgJdDjFPjgFlg9e8fsq084iGO7Z3HLm98wc8Vm/+oTkXqn6+CbCzM47d+QmgWvXAplRQAEA8Z95/alXUYyv3pmBusLS30uVETqS4MEvHNusnPulIbYl9QgpTWc+QhsXAbvXL9jdsuUBB4aM4CCknKufHYmZRXV/iYuIk2IzuCbm85Hw9BrYdYzMHv8jtk992/B38/qzdTlm7j5zW/0o6tIDFDAN0fH3Aidjoa3/w/WLdgx+/S+7fnVsV0ZP3WFep4UiQEK+OYoGAdnjYPEdHjpQijdumPRdcO6c8LB2dz29gLd6SrSxCngm6v0tnD2ONi4FN7+HUSaZAIB477z+tEtK41fPzuT7zcU+VyoiOwtBXxz1nko/OQPMO8lmPHEjtlpiXE8duFAAga/eGqahvsTaaIU8M3dUddA1+PhnRt2uj6+Q+sUHhwzgB82FnPV+FmEwvrRVaSpUcA3d4EAnPmod338SxdCyY8jPh3eJZPbTu/F5MXrufMddQgq0tQo4AVSM+GcJ6FgFbx62Y7+agBGH3YAFw7pyKOffc9zU9SdgUhTooAXT4fBMPxOWDIJJv9tp0U3ndKTn3TP4qY35jN5cZ5PBYpIXSng5UcDL4V+Y+DTu2DhjwNwxQUD/Ht0f7q3Tec3z81iweotPhYpIrWlgJcfmcGIf8L+/b2uhdd/u2NRWmIcj180iLTEOC55chprC7b5WKiI1IYCXnYWnwTnPg1xifD8aNj249n6fhlJPH7RIAq3lXPJk9PYWlrhY6EisicKeNldRg6Mego2fbfTICHg9Vnz3/P7s3hdIb95biYVIXVMJtJYKeClap2O8gYJWTwBPvn7TouO7Z7NbacfwuTF67nlLXVMJtJYxfldgDRih10Ba+bAJ3dC1kHQ66wdi84/rCMrNhbz8Kff0S4jmSt/0s3HQkWkKgp4qZ4ZnHqf11Tz+q+hVSdoP2DH4htO7sG6Ldv4x3uLyUxN4LzBB/hXq4jsRk00UrO4RDjvWUjLhvGjvZuhIgIB466z+zD0oCz+8No8Jn2z1sdCRWRXCnjZs9Q28LMXvGH+xp+3Y7g/gIS4AA+e359Dc1ry2/GzmPr9Jh8LFZHKFPBSO217wtmPw7r58NoVO11Zk5oYxxMXDaJ9q2QufWoaC9foRiiRxkABL7V30DAY9hdY+BZ8/JedFrVOTeB/lwwmNSGOCx+fyspNxT4VKSLbKeClbg7/NfS/ED77J8x4cqdFOa1S+N+lgymtCHP+Y1N0t6uIzxTwUjdmMPKf0O0EePv38O2knRYf1Dadpy4ZzKaiMkY/9jXrC0t9KlREFPBSd8F4r3vhtofASxfB6lk7Le7boSWPXzSI1fklXDBuCvnFZb6UKdLcKeBl7ySmw/kvQUomPDsKNi/fafHgzq157OeD+G5DEReMm6ph/0R8oICXvZe+H4x5GUJl8MzZULzzJZJHHdiGB8/vz8I1W7j4iWkUqXMykQalgJd9k9UdfvY85K+A8T+D8pKdFh9/cFvu/1k/Zq3YzKVPKeRFGpICXvZdxyFw5sOwcgq8eCGEdm6OGXFoO+49ty9Tv9/ERU9MVTfDIg1EAS/145Az4JR7YMl78PqvdroRCuD0vu3513n9mLkin5+Pm6I2eZEGoICX+jPwEjj+Zpj3Eky8FnbpRvjUPvvz39H9mJtbwAWPTaGgWCEvEk0KeKlfR/8ejvwdTB8HH9622+KTe7XjoTEDWLimkNGPfc2mIl1CKRItCnipfyfcAgMuhs/vgS/+tfvinm155OcDWJK3lXMe+pLV+SW7rSMi+04BL/Vv+92uh5wJ7/8Zpo3bbZVju2fz9CWDydtSylkPfsnSvEIfChWJbQp4iY5AEM54GA46GSb8HqY/sdsqh3XJ5PkrDqc85Djnoa+YvTLfh0JFYpcCXqInLgFG/Q8OHAZv/263zskADtk/g1d+NYT0pHhGP/o1n367vuHrFIlRCniJrrhEGPU0dDsR3roaZjy12yodM1N5+ZdD6JiZyiVPTuOFaSt8KFQk9ijgJfrik+DcZ7weKN+6Cmb+b7dVslsk8cIVhzOkayY3vDKPv01cSDjsqtiYiNSWAl4aRnwSnPssdD0e3vwtTH10t1VaJMXzxEWDuODwjjz86Xf88pkZFJfprleRvRW1gDezJDObamZzzOwbM7s1WvuSJiI+Cc57Dg4a7t0I9dk9u60SFwxw2+mHcPOpPflg4TpGPfyVBg4R2UvRPIMvBY5zzvUB+gInm9nhUdyfNAXxSXDu09DrbPjwVvjglt3ueDUzLj6yM49dOJDv1xdxyr8/46tlG/2pV6QJi1rAO8/WyMv4yEONquINGHLmIzDgIvj8Xu9sfpe+awCO69GW1688khbJ8YwZN4WHP1mGc/oTEqmtqLbBm1nQzGYDecD7zrkpVaxzuZlNN7Pp69frErlmIxCEU+6DI66CaY/Bq5dBxe7D+x3YNp03rjySYT3b8rd3FvGrZ2ZSqI7KRGolqgHvnAs55/oCOcBgM+tVxTqPOOcGOucGZmVlRbMcaWzM4MTbvA7K5r8MT58JJZt3Wy09KZ4Hzu/PH0cczPsL13H6f75g/qoCHwoWaVoa5Coa51w+MBk4uSH2J02ImddB2ccs1KsAAA74SURBVJmPef3JjzvJGzxkt9WMy4Z24dlfHEZRWQVnPPAFj3y6TJdSitQgmlfRZJlZy8h0MnACsCha+5Mmrvc5cMFrsHUtPHbCbgN5b3d4l0zevXoox/XI5o6JixgzboqushGpRjTP4NsBH5vZXGAaXhv821HcnzR1nY+GSyZBMBGeGAkL3qxytVapCTw0ZgB/P+tQZq3IZ9i9n/Di9JX6AVZkF9aY/lEMHDjQTZ8+3e8yxG+F6+D50bBqOgy9Do79AwSqPhf5fkMR1788h2nLN3P0gW2444xD6dA6pYELFvGPmc1wzg2sapnuZJXGJ70tXDwR+o2BT/8B48+Dkqp7muzcJpUXLh/C7acfwswfNnPSfZ8y7vPvKQ/tftmlSHOjgJfGKS4RTvsPjLgbln0Ijx4HeVX/hBMIGBcM6cR7/zeUwZ1bc/vbCxh5/2d8uXRDAxct0rgo4KXxMoPBl8GFb0HpFi/kZ4+vdvWcVik8cdEgHrlgACXlIUY/NoVfPzuDlZuKG7BokcZDbfDSNGxZDa9cBj98Dr3Pg5F3Q2J6tatvKw/xyKff8cDkpYTCjvMP68hvjutGm7TEBixaJPpqaoNXwEvTEQ7Bp3fDJ3dCq85w9jjYv1+Nb1lTUML9Hy7hxem5JMYF+MVRnbn0qC5kpMQ3UNEi0aWAl9iy/Auva4PCtTD0Wjj6Wm/0qBosW7+VeyZ9y4R5a0hLjOP8ww/g0iM7k90iqYGKFokOBbzEnpLN8O5YmDMe2h4KP30A2vXe49u+WV3Ag5OXMXHeGuKCAc4ekMPFR3TiwLbVN/eINGYKeIldiyZ6470Wb4Qjr/bO5hP2fB388g1FPPzpd7wyI5eyUJghXTL5+ZCOnNCzLfFBXXsgTYcCXmJb8SZ47w/e2XzGATDiLug+vFZv3bi1lBemr+TZr1ewKr+E7PRETu+7P2f0y6Hn/i2iXLjIvlPAS/Ow/HOYcA2sX+SNGnXSXyGza63eGgo7PlqUxwvTVjJ5cR4VYUeP/dL5ab/2nNK7HTmtdHesNE4KeGk+QuXw9YMw+U4IlcLAS2Do9ZBW+66oNxWV8fbc1bw6cxWzV3p30B7crgUnHpzNiT33o1f7FphZtD6BSJ0o4KX52ZrnhfyMJyE+BY68Cg77JSTVrdll+YYiJi1YywcL8pj+wybCDvZrkcQR3TIZ0iWTI7q1oX3L5Oh8BpFaUMBL87VhiTfu66K3ISkDDvsVHHYFpLSu86Y2FZXx0aI8Pl6Ux1ffbWRTURkAB7ROYXDn1vTJyaBPh5b02K8FCXH6oVYahgJeZPUs7yapRW9DQprXdDP4Mmh5wF5tLhx2fJtXyFfLNvLlso3M/GEzGyOBnxAM0HP/FvTOyeDAtukclJ3GQW3TaZVa87X6IntDAS+y3boF8Nnd8M1r3useI72mm45Hen3f7CXnHLmbS5ibW8Cc3Hxmr8znm1UFFJWFdqzTJi2RA7PT6NQmhQ6tU+jQKoUDWnvTrVLi1a4ve0UBL7Kr/JUwfZzXRl+yGbJ6QN/R0PtcSN+vXnbhnGN1wTa+XVfI0nVb+XZdIUvytrJyU/GOs/3t0hLjaNsikez0JLJbJJKd7k1npXvTrVITyEiOp2VKPMnxQX0ZyA4KeJHqlJfAvJdh1tPemLAWgK7Hw6Fnw0EnQXKrqOy2qLSClZuLWbmphJWbilmxqZi8wm3kbSklr7CUvMJtbCuvuk/7hGCAFpGwb5kcT0ZyPC2S40lOCJKaECQlIY7URO85pYrXSfFBEuICJMYFSIgLkBD0pvWl0TQp4EVqY8NS72apOc/DllwIxEHnodDjFK8pp57O7GvDOUdhaUUk8LdRUFxOfkk5BSXl5Bd7zwUlZeQXe6+3llZQXFZBcVmI4krNQnWxPegTIo/EHc/eF0J80IgPBogLGHGVnuMDRnD7dNCb3n09Iz4QiCzz5u+YDnjrBCPrBcybDgaMYOXpgLcsLrjz/MrzAgEjLuA9B3fZTiAQm19gCniRugiHYfVMWPgWLHwTNn3nzW/bC7ocC52PgY5HQGKan1VWKxx2lJSHKCqroKQsRFFpiOKyCorKQhSXVlBaEaasIkxpRYjSinCl195zWShEaXmYslD4x+eKEGUVYSrCjoqQizx7r8tDYUJhR3nIUREOEwo5ysPhHes1Fmbs9CUQNCO46xdD5Euhqi+Jyu8LBCAuEIisA8FAgGA184KVtlvV9gMBIz0xjsuGdtnLz6WAF9k7zkHeQvj2HfjuE1jxtXcDVSDO66q4/UDIiTxadtynH2pjkXOOUDjyhRD5Utj+RVD5i6I85AhXWnf79G6PSvPDzvuyCTlHuLr3OUdol3WqmrfTvsOOkINQOBzZTmTaEVk/TDgMIffj+j++r+qaKy/bdb2wg6z0RKb98YS9OsYKeJH6Ul7ihfz3n8CKKd7llxUl3rKUNrBfL8juCdkHe89Z3WscmETEOS/kg3vZhFRTwMftU2UizU18MnT9ifcAr2uEvAWQOw1WzYK8b2D6Ez+GPkB6O+/svlUnaNUxMt0RMnIgNbtWvV9K7DLzmnSiQQEvsi+C8dCuj/cYFJkXDkP+cq9pJ28BbPoeNi/3OkOb+wKwy/+aE9IhLRvS2kaesyEl07vztqpHYguv+4VgvJqEpEYKeJH6FghA6y7eo8fInZdVlEHBSi/wC9d4feZszYOt67zndd/Aso+htGDP+7GgF/TxSd7/LOJTIC4pMi/ZewTivC+CQDwE4yLP8T/ODyZUsSzobdsCPz4Cu7zeq2VB7wvJzHtNbabZZX4g8qVW07TVvE61+4u9L0sFvEhDikvwujDeUzfG4RCUboFtBVU/yksqPYqhYpv3vH3etgJvSMNwudeMFK6IPJdDqCLyXObNl0pq+wUUAINqv0SqnN5l/crbTWkDl7xT759GAS/SGAWC3k1WUbrRagfnqgj/CnDhSo9Q5Nl5XzxVLgt7TVN7XBbytoP7cZu7Tbua13HhSuuFq3hPTeuEK22LPdRR1TS1qGNPNVWx3Tr2clpbCniR5sws0lQT73clEgXq01REJEYp4EVEYpQCXkQkRingRURilAJeRCRGKeBFRGKUAl5EJEYp4EVEYlSj6i7YzNYDP+zl29sAG+qxnPqiuupGddVNY60LGm9tsVZXR+dcVlULGlXA7wszm15dn8h+Ul11o7rqprHWBY23tuZUl5poRERilAJeRCRGxVLAP+J3AdVQXXWjuuqmsdYFjbe2ZlNXzLTBi4jIzmLpDF5ERCpRwIuIxKgmH/BmdrKZLTazpWZ2o8+1LDezeWY228ymR+a1NrP3zWxJ5DnKQ/TsqOVxM8szs/mV5lVbi5mNjRzDxWZ2UgPXdYuZrYoct9lmNsKHujqY2cdmttDMvjGzqyPzfT1mNdTl6zEzsyQzm2pmcyJ13RqZ7/fxqq4u3//GIvsKmtksM3s78jq6x8s512QfQBBYBnQBEoA5QE8f61kOtNll3l3AjZHpG4G/N1AtQ4H+wPw91QL0jBy7RKBz5JgGG7CuW4Brq1i3IetqB/SPTKcD30b27+sxq6EuX48Z3gijaZHpeGAKcHgjOF7V1eX731hkf78HngPejryO6vFq6mfwg4GlzrnvnHNlwPPA6T7XtKvTgaci008BP22InTrnPgU21bKW04HnnXOlzrnvgaV4x7ah6qpOQ9a1xjk3MzJdCCwE2uPzMauhruo0VF3OObc18jI+8nD4f7yqq6s6DfY3ZmY5wEjgsV32H7Xj1dQDvj2wstLrXGr+4482B0wysxlmdnlkXlvn3Brw/rEC2b5VV30tjeE4/sbM5kaacLb/N9WXusysE9AP7+yv0RyzXeoCn49ZpLlhNpAHvO+caxTHq5q6wP+/sfuA64FwpXlRPV5NPeCtinl+Xvd5pHOuPzAcuNLMhvpYS134fRwfBLoCfYE1wD8j8xu8LjNLA14Bfuec21LTqlXMi1ptVdTl+zFzzoWcc32BHGCwmfWqYXW/6/L1eJnZKUCec25Gbd9Sxbw619XUAz4X6FDpdQ6w2qdacM6tjjznAa/h/ZdqnZm1A4g85/lVXw21+HocnXPrIv8ow8Cj/Phf0Qaty8zi8UL0Wefcq5HZvh+zqupqLMcsUks+MBk4mUZwvKqqqxEcryOB08xsOV5T8nFm9gxRPl5NPeCnAQeaWWczSwDOA970oxAzSzWz9O3TwDBgfqSeCyOrXQi84Ud9EdXV8iZwnpklmlln4EBgakMVtf0PPOIMvOPWoHWZmQHjgIXOuXsqLfL1mFVXl9/HzMyyzKxlZDoZOAFYhP/Hq8q6/D5ezrmxzrkc51wnvJz6yDk3hmgfr2j9WtxQD2AE3pUFy4A/+lhHF7xfvecA32yvBcgEPgSWRJ5bN1A94/H+K1qOdzZwaU21AH+MHMPFwPAGrutpYB4wN/KH3c6Huo7C+y/wXGB25DHC72NWQ12+HjOgNzArsv/5wJ/39Pfuc12+/41V2t+x/HgVTVSPl7oqEBGJUU29iUZERKqhgBcRiVEKeBGRGKWAFxGJUQp4EZEYpYAXqQdmduz2HgJFGgsFvIhIjFLAS7NiZmMi/YXPNrOHIx1TbTWzf5rZTDP70MyyIuv2NbOvIx1Uvba9gyoz62ZmH0T6HJ9pZl0jm08zs5fNbJGZPRu5C1XENwp4aTbM7GDgXLxO4foCIeB8IBWY6byO4j4Bbo685X/ADc653nh3QW6f/yzwX+dcH+AIvDtzwevp8Xd4fXl3wet/RMQ3cX4XINKAjgcGANMiJ9fJeJ07hYEXIus8A7xqZhlAS+fcJ5H5TwEvRfobau+cew3AObcNILK9qc653Mjr2UAn4PPofyyRqingpTkx4Cnn3NidZprdtMt6NfXfUVOzS2ml6RD69yU+UxONNCcfAmebWTbsGA+zI96/g7Mj64wGPnfOFQCbzezoyPwLgE+c1xd7rpn9NLKNRDNLadBPIVJLOsOQZsM5t8DM/oQ36lYAr0fLK4Ei4BAzmwEU4LXTg9d960ORAP8OuDgy/wLgYTO7LbKNcxrwY4jUmnqTlGbPzLY659L8rkOkvqmJRkQkRukMXkQkRukMXkQkRingRURilAJeRCRGKeBFRGKUAl5EJEb9PypL2+9deuI3AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#  print(history.history.keys())\n",
    "\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions            :    [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "Actual                 :    [3 1 1 3 1 1 0 4 1 3 2 3 1 0 0 3 0 4 3 0 1 3 0 2 1 3]\n",
      "R-squared              :    -0.054054054054053946\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "predictions = model.predict(x=X_test, batch_size=4, verbose=0) \n",
    "rounded_predictions = np.array([int(i[0]) for i in np.round(predictions).tolist()])\n",
    "score = r2_score(y_test, rounded_predictions)\n",
    "print(\"Predictions            :   \",rounded_predictions)\n",
    "print(\"Actual                 :   \",y_test)\n",
    "print(\"R-squared              :   \",score)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 8]\n",
      " [1 6]\n",
      " [2 2]\n",
      " [3 3]\n",
      " [4 7]]\n"
     ]
    }
   ],
   "source": [
    "# Values count\n",
    "(unique, counts) = np.unique(y_test, return_counts=True)\n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "print(frequencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 2 3 3 0]\n",
      " [0 3 0 3 0]\n",
      " [0 0 1 0 1]\n",
      " [0 1 2 0 0]\n",
      " [1 2 2 2 0]]\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_true=y_test, y_pred=rounded_predictions)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[0 1 2 1 0]\n",
      " [0 1 5 1 0]\n",
      " [0 0 2 0 0]\n",
      " [0 0 1 0 2]\n",
      " [0 0 4 4 2]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm_plot_labels = ['0','1','2','3','4']\n",
    "plot_confusion_matrix(cm=cm, classes=cm_plot_labels, title='Confusion Matrixx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
